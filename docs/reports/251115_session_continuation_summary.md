# Session Continuation Summary - ML Keypoint Detection Manual Labeling Preparation

**ë‚ ì§œ**: 2025-11-15
**ì‘ì—… ì‹œê°„**: ~1ì‹œê°„
**ìƒíƒœ**: Manual Labeling ì¤€ë¹„ ì™„ë£Œ, ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰ ì¤€ë¹„ë¨

---

## âœ… ì´ë²ˆ ì„¸ì…˜ ì™„ë£Œ ì‘ì—…

### 1. ì´ì „ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë³µêµ¬ (100% ì™„ë£Œ)

**ì‘ì—… ë‚´ìš©**:
- 2025-11-14 ì„¸ì…˜ì—ì„œ ì§„í–‰ëœ ML Keypoint Detection í†µí•© ì‘ì—… ì „ì²´ ì´í•´
- Phase 1: YOLOv8-Pose Infrastructure ì™„ë£Œ ìƒíƒœ í™•ì¸
- Phase 2: SuperAnimal Integration 90% ì™„ë£Œ, DLC API ì´ìŠˆ í™•ì¸
- Phase 3: Manual Labeling ì¤€ë¹„ ì™„ë£Œ í™•ì¸

**ì£¼ìš” ë°œê²¬ì‚¬í•­**:
- YOLOv8 í•™ìŠµ: mAP ~0 (geometric labels í’ˆì§ˆ ë¬¸ì œë¡œ ì˜ˆìƒëœ ì‹¤íŒ¨)
- SuperAnimal: DLC 2.3.11 TensorFlow APIëŠ” ë‹¨ì¼ ì´ë¯¸ì§€ ë¯¸ì§€ì›, DLC 3.0 PyTorch í•„ìš”
- Geometric fallback: 15/22 keypoints, conf=0.5ë¡œ ì˜ˆìƒë³´ë‹¤ ì–‘í˜¸í•œ ì„±ëŠ¥
- **Manual labelingì´ ê°€ì¥ í˜„ì‹¤ì ì´ê³  íš¨ê³¼ì ì¸ ì ‘ê·¼**ìœ¼ë¡œ ê²°ë¡ 

### 2. Manual Labeling ì›Œí¬í”Œë¡œìš° ë¬¸ì„œí™” (100% ì™„ë£Œ)

**ìƒì„±ëœ ë¬¸ì„œ**:
1. `QUICK_START_LABELING.md` (307 lines)
   - ì „ì²´ ì›Œí¬í”Œë¡œìš°: ë¼ë²¨ë§ â†’ í•™ìŠµ â†’ í‰ê°€ â†’ í†µí•©
   - ì˜ˆìƒ ì‹œê°„: ì´ 3-4ì‹œê°„ (ë¼ë²¨ë§ 2-3ì‹œê°„, í•™ìŠµ 30ë¶„)
   - ì˜ˆìƒ ê°œì„ : mAP 0â†’0.6-0.8, Paw detection 0%â†’70-80%

2. `docs/ROBOFLOW_LABELING_GUIDE.md` (263 lines)
   - Roboflow íŠ¹í™” ê°€ì´ë“œ
   - 22 keypoints ì •í™•í•œ ìˆœì„œ ì •ì˜
   - Setup â†’ Labeling â†’ Export â†’ Validation â†’ Training ì „ì²´ ê³¼ì •
   - ìƒì„¸í•œ keypoint placement ê°€ì´ë“œ

3. `docs/MANUAL_LABELING_GUIDE.md` (ì´ì „ ì„¸ì…˜ ìƒì„±)
   - ì¼ë°˜ì ì¸ manual labeling ê°€ì´ë“œ
   - ë‹¤ì–‘í•œ ë„êµ¬ ì˜µì…˜ (Roboflow, Label Studio, CVAT)

**í•µì‹¬ ë„êµ¬**:
- `sample_images_for_labeling.py`: 20ê°œ ì´ë¯¸ì§€ ìƒ˜í”Œë§ ì™„ë£Œ
- `preprocessing_utils/visualize_yolo_labels.py`: ë¼ë²¨ ê²€ì¦ìš© ì‹œê°í™”

### 3. Manual Labeling ë°ì´í„°ì…‹ ì¤€ë¹„ (100% ì™„ë£Œ)

**ìƒ˜í”Œë§ ê²°ê³¼**:
- ìœ„ì¹˜: `data/manual_labeling/images/`
- íŒŒì¼: `sample_000.png` ~ `sample_019.png` (20ê°œ)
- í¬ê¸°: ê° 57KB ~ 82KB
- ìƒíƒœ: ë¼ë²¨ë§ ì¤€ë¹„ ì™„ë£Œ âœ…

**ë””ë ‰í† ë¦¬ êµ¬ì¡°**:
```
data/manual_labeling/
â”œâ”€â”€ images/           # 20 images âœ…
â”œâ”€â”€ masks/            # 20 masks âœ…
â”œâ”€â”€ labels/           # (ë¼ë²¨ë§ í›„ ìƒì„± ì˜ˆì •)
â””â”€â”€ viz/              # (ê²€ì¦ ì‹œê°í™” ì €ì¥ ì˜ˆì •)
```

### 4. 22 Keypoint ì •ì˜ í‘œì¤€í™” (100% ì™„ë£Œ)

**MAMMAL 22 Keypoints ìˆœì„œ (Critical: ìˆœì„œ ì •í™•íˆ ì§€í‚¬ ê²ƒ!)**:
```
Head (0-5):
  0: nose, 1: left_ear, 2: right_ear, 3: left_eye,
  4: right_eye, 5: head_center

Spine (6-13):
  6-13: spine_1 to spine_8 (neck â†’ tail base, ê· ë“± ë¶„í¬)

Paws (14-17):
  14: left_front_paw, 15: right_front_paw,
  16: left_rear_paw, 17: right_rear_paw

Tail (18-20):
  18: tail_base, 19: tail_mid, 20: tail_tip

Body (21):
  21: centroid
```

---

## ğŸ“Š ì˜ˆìƒ ê°œì„  íš¨ê³¼

### Before (Geometric Baseline)
```
Detected: 15/22 keypoints
Confidence: 0.40-0.60
Paw detection: 0%
Loss: ~300K
mAP: ~0
```

### After (Manual Labels + Fine-tuned YOLO)
```
Detected: 20-22/22 keypoints
Confidence: 0.80-0.95 (2Ã— improvement)
Paw detection: 70-80%
Loss: 15K-30K (10-20Ã— improvement)
mAP: 0.6-0.8
```

---

## ğŸ¯ ë‹¤ìŒ ì¦‰ì‹œ ì‹¤í–‰ ë‹¨ê³„ (Recommended Workflow)

### Step 1: Roboflow ê³„ì • ë° í”„ë¡œì íŠ¸ ìƒì„± (5ë¶„)

1. https://roboflow.com/ ì ‘ì† ë° ê°€ì…
2. "Create New Project" í´ë¦­
3. Project Type: **Keypoint Detection** ì„ íƒ
4. Project Name: `MAMMAL_Mouse_Keypoints`

### Step 2: 22 Keypoints ì •ì˜ (2ë¶„)

**ì¤‘ìš”**: ì •í™•í•œ ìˆœì„œë¡œ ì…ë ¥!

```
0:  nose
1:  left_ear
2:  right_ear
3:  left_eye
4:  right_eye
5:  head_center
6:  spine_1
7:  spine_2
8:  spine_3
9:  spine_4
10: spine_5
11: spine_6
12: spine_7
13: spine_8
14: left_front_paw
15: right_front_paw
16: left_rear_paw
17: right_rear_paw
18: tail_base
19: tail_mid
20: tail_tip
21: centroid
```

### Step 3: ì´ë¯¸ì§€ ì—…ë¡œë“œ (2ë¶„)

```bash
# Roboflow Upload UIì—ì„œ:
# 1. "Upload" â†’ "Upload Images" í´ë¦­
# 2. ë‹¤ìŒ ê²½ë¡œì—ì„œ ëª¨ë“  20ê°œ ì´ë¯¸ì§€ ì„ íƒ:
#    /home/joon/dev/MAMMAL_mouse/data/manual_labeling/images/
# 3. ì—…ë¡œë“œ ì™„ë£Œ ëŒ€ê¸°
```

### Step 4: ë¼ë²¨ë§ (2-3ì‹œê°„)

**ë¼ë²¨ë§ íŒ**:
- ì´ë¯¸ì§€ë‹¹ ì•½ 5-10ë¶„ ì†Œìš”
- 5ê°œ ì´ë¯¸ì§€ë§ˆë‹¤ 5ë¶„ íœ´ì‹
- ì¤Œ ì¸í•˜ì—¬ ì •ë°€í•˜ê²Œ ë°°ì¹˜
- Maskë¥¼ ì°¸ê³ ë¡œ í™œìš© ê°€ëŠ¥ (í•„ìˆ˜ ì•„ë‹˜)

**í’ˆì§ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ê° ì´ë¯¸ì§€ë§ˆë‹¤)**:
- [ ] 22ê°œ keypoints ëª¨ë‘ ë°°ì¹˜
- [ ] Left/right í˜¼ë™ ì—†ìŒ
- [ ] Spine 8ê°œê°€ ìì—°ìŠ¤ëŸ½ê²Œ ê· ë“± ë¶„í¬
- [ ] PawsëŠ” ê´€ì ˆ ì¤‘ì‹¬ì— ë°°ì¹˜ (ë°œë ì•„ë‹˜)
- [ ] Tailì€ ìì—°ìŠ¤ëŸ¬ìš´ ê³¡ì„  ë”°ë¦„

### Step 5: Export ë° ê²€ì¦ (5ë¶„)

```bash
# Roboflowì—ì„œ:
# 1. "Generate" ë²„ì „ ìƒì„±
# 2. Export Format: "YOLO v8" ì„ íƒ
# 3. ZIP ë‹¤ìš´ë¡œë“œ

# í„°ë¯¸ë„ì—ì„œ:
cd ~/Downloads
unzip roboflow.zip -d ~/dev/MAMMAL_mouse/data/manual_labeling/roboflow_export

# ë¼ë²¨ ë³µì‚¬
cp -r data/manual_labeling/roboflow_export/train/labels/* \
      data/manual_labeling/labels/

# ë¼ë²¨ ê²€ì¦ ì‹œê°í™” (ì²« 5ê°œ)
~/miniconda3/envs/mammal_stable/bin/python \
  preprocessing_utils/visualize_yolo_labels.py \
  --images data/manual_labeling/images \
  --labels data/manual_labeling/labels \
  --output data/manual_labeling/viz \
  --max_images 5

# ê²°ê³¼ í™•ì¸
ls data/manual_labeling/viz/
```

### Step 6: ë°ì´í„°ì…‹ ë³‘í•© (2ë¶„)

```bash
# Manual (20) + Geometric (50) = 70 total
python preprocessing_utils/merge_datasets.py \
  --manual data/manual_labeling \
  --geometric data/yolo_mouse_pose \
  --output data/yolo_mouse_pose_enhanced \
  --train_split 0.8

# ê²°ê³¼: 56 train + 14 val
```

### Step 7: YOLOv8 Fine-tuning (30ë¶„)

```bash
# Enhanced datasetë¡œ fine-tune
~/miniconda3/envs/mammal_stable/bin/python scripts/train_yolo_pose.py \
  --data data/yolo_mouse_pose_enhanced/data.yaml \
  --epochs 100 \
  --batch 8 \
  --imgsz 256 \
  --weights yolov8n-pose.pt \
  --name mammal_mouse_finetuned

# í•™ìŠµ ëª¨ë‹ˆí„°ë§ (ë‹¤ë¥¸ í„°ë¯¸ë„)
tail -f /tmp/yolo_train.log
```

### Step 8: í‰ê°€ ë° ë¹„êµ (10ë¶„)

```bash
# Validation set í‰ê°€
~/miniconda3/envs/mammal_stable/bin/python -c "
from ultralytics import YOLO

model = YOLO('runs/pose/mammal_mouse_finetuned/weights/best.pt')
metrics = model.val(data='data/yolo_mouse_pose_enhanced/data.yaml')

print(f'mAP50: {metrics.box.map50:.3f}')
print(f'mAP50-95: {metrics.box.map:.3f}')
"

# Geometric vs YOLO ì‹œê°ì  ë¹„êµ
~/miniconda3/envs/mammal_stable/bin/python fit_monocular.py \
  --input_dir data/manual_labeling/images \
  --output_dir results/yolo_finetuned \
  --detector yolo \
  --yolo_weights runs/pose/mammal_mouse_finetuned/weights/best.pt \
  --max_images 5
```

### Step 9: Production í†µí•© (5ë¶„)

```bash
# Best modelì„ models/ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
cp runs/pose/mammal_mouse_finetuned/weights/best.pt \
   models/yolo_mouse_pose_finetuned.pt

# fit_monocular.py ê¸°ë³¸ê°’ ì—…ë°ì´íŠ¸ (optional)
# --detector ê¸°ë³¸ê°’ì„ 'yolo'ë¡œ
# --yolo_weights ê¸°ë³¸ê°’ì„ 'models/yolo_mouse_pose_finetuned.pt'ë¡œ
```

---

## ğŸ“ ì°¸ì¡° ë¬¸ì„œ ë° íŒŒì¼

### ë¬¸ì„œ
- **Quick Start**: `QUICK_START_LABELING.md`
- **Roboflow Guide**: `docs/ROBOFLOW_LABELING_GUIDE.md`
- **General Guide**: `docs/MANUAL_LABELING_GUIDE.md`
- **ì´ì „ ì„¸ì…˜**: `docs/reports/251114_session_summary.md`

### ì½”ë“œ
- **ìƒ˜í”Œë§**: `sample_images_for_labeling.py`
- **ì‹œê°í™”**: `preprocessing_utils/visualize_yolo_labels.py`
- **í•™ìŠµ**: `train_yolo_pose.py`
- **Detector**: `preprocessing_utils/yolo_keypoint_detector.py`
- **í†µí•©**: `fit_monocular.py`

### ë°ì´í„°
- **ìƒ˜í”Œ ì´ë¯¸ì§€**: `data/manual_labeling/images/` (20ê°œ ì¤€ë¹„ ì™„ë£Œ âœ…)
- **ìƒ˜í”Œ ë§ˆìŠ¤í¬**: `data/manual_labeling/masks/` (20ê°œ)
- **Geometric ë°ì´í„°**: `data/yolo_mouse_pose/` (50 train, 10 val)

---

## ğŸ”§ Troubleshooting

### Roboflow ì ‘ì† ì•ˆë¨
- ì¸í„°ë„· ì—°ê²° í™•ì¸
- ë‹¤ë¥¸ ë¸Œë¼ìš°ì € ì‹œë„
- VPN ë¹„í™œì„±í™”

### Export í˜•ì‹ ì˜¤ë¥˜
- **ë°˜ë“œì‹œ YOLO v8 ì„ íƒ** (v5, v7 ì•„ë‹˜)
- ê° .txt íŒŒì¼: 1 class + 4 bbox + 66 values (22Ã—3 keypoints)

### í•™ìŠµ ì‹¤íŒ¨
- CUDA í™•ì¸: `python -c "import torch; print(torch.cuda.is_available())"`
- Batch size ê°ì†Œ: `--batch 4`
- data.yaml ê²½ë¡œ í™•ì¸

### mAP ë‚®ìŒ (<0.3)
- ë¼ë²¨ í’ˆì§ˆ ì¬í™•ì¸ (ì‹œê°í™”ë¡œ ê²€ì¦)
- Epochs ì¦ê°€: `--epochs 200`
- ì¶”ê°€ ì´ë¯¸ì§€ ë¼ë²¨ë§ (10ê°œ ë”)

---

## ğŸ’¡ í•µì‹¬ êµí›ˆ (ì´ì „ ì„¸ì…˜ì—ì„œ)

### 1. Data Quality > Algorithm
- Geometric keypointsë¡œ YOLOv8 í•™ìŠµ â†’ ì™„ì „ ì‹¤íŒ¨ (mAP ~0)
- **êµí›ˆ**: ML ëª¨ë¸ì€ í•™ìŠµ ë°ì´í„° í’ˆì§ˆì— ì ˆëŒ€ ì˜ì¡´
- **í•´ê²°**: Manual labelingì´ ìœ ì¼í•œ í˜„ì‹¤ì  í•´ê²°ì±…

### 2. Pretrained Modelsì˜ í•œê³„
- SuperAnimal-TopViewMouse: ì¢‹ì€ ëª¨ë¸ì´ì§€ë§Œ API ì œì•½
- DLC 2.3.11: ë‹¨ì¼ ì´ë¯¸ì§€ inference ë¯¸ì§€ì›
- DLC 3.0 PyTorch: ì•„ì§ ì •ì‹ ë¦´ë¦¬ìŠ¤ ì•ˆë¨
- **êµí›ˆ**: ì¢‹ì€ ë„êµ¬ë„ ì‹¤ìš©ì„±ì´ ì¤‘ìš”

### 3. Manual Labelingì˜ ROI
- íˆ¬ì: 2-3ì‹œê°„ (20 images Ã— 5-10 min)
- ì˜ˆìƒ ìˆ˜ìµ:
  - Confidence 2ë°° í–¥ìƒ (0.5 â†’ 0.85+)
  - Loss 10-20ë°° ê°ì†Œ (300K â†’ 15-30K)
  - Paw detection 0% â†’ 70-80%
- **ROI**: ë§¤ìš° ë†’ìŒ (ì‹œê°„ ëŒ€ë¹„ ì„±ëŠ¥ ê°œì„ )

### 4. Progressive Workflow
1. Geometric baseline (ì™„ë£Œ) â†’ ë¹ ë¥´ê²Œ PoC ê²€ì¦
2. Pretrained models íƒìƒ‰ (ì™„ë£Œ) â†’ í•œê³„ ë°œê²¬
3. Manual labeling (ë‹¤ìŒ) â†’ ì‹¤ìš©ì  í•´ê²°ì±…
4. Fine-tuning (ì˜ˆì •) â†’ ìµœì¢… ì„±ëŠ¥ ë‹¬ì„±

---

## âœ… Success Criteria

ë¼ë²¨ë§ ë° í•™ìŠµ ì™„ë£Œ í›„ í™•ì¸ ì‚¬í•­:

- [ ] 20ê°œ ì´ë¯¸ì§€, ê° 22 keypoints ë¼ë²¨ë§ ì™„ë£Œ
- [ ] ì‹œê°í™”ë¡œ ë¼ë²¨ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ
- [ ] YOLOv8 í•™ìŠµ 100 epochs ì™„ë£Œ
- [ ] **mAP > 0.6 ë‹¬ì„±**
- [ ] **Paw detection ì‘ë™** (confidence > 0.7)
- [ ] fit_monocular.pyì— í†µí•©
- [ ] ìƒˆ ì´ë¯¸ì§€ì—ì„œ í…ŒìŠ¤íŠ¸ ì„±ê³µ

---

## ğŸš€ ì´í›„ ê°œì„  ê³„íš (Optional)

1. **ë¼ë²¨ 30ê°œ ë” ì¶”ê°€** â†’ mAP 0.8+ ëª©í‘œ
2. **Hyperparameter íŠœë‹** â†’ Epochs, batch size, augmentation
3. **Augmentation ê°•í™”** â†’ Rotation, flip, scale, mosaic
4. **ONNX Export** â†’ ë¹ ë¥¸ inference
5. **Ensemble** â†’ Geometric + YOLO ì¡°í•©í•˜ì—¬ robustness

---

## ğŸ“ˆ Timeline

| ë‹¨ê³„ | ì˜ˆìƒ ì‹œê°„ | ìƒíƒœ |
|------|----------|------|
| Roboflow ì„¤ì • | 5ë¶„ | ëŒ€ê¸° ì¤‘ |
| 22 keypoints ì •ì˜ | 2ë¶„ | ëŒ€ê¸° ì¤‘ |
| ì´ë¯¸ì§€ ì—…ë¡œë“œ | 2ë¶„ | ëŒ€ê¸° ì¤‘ |
| ë¼ë²¨ë§ (20 images) | 2-3ì‹œê°„ | ëŒ€ê¸° ì¤‘ |
| Export & ê²€ì¦ | 5ë¶„ | ëŒ€ê¸° ì¤‘ |
| ë°ì´í„°ì…‹ ë³‘í•© | 2ë¶„ | ëŒ€ê¸° ì¤‘ |
| YOLOv8 í•™ìŠµ | 30ë¶„ | ëŒ€ê¸° ì¤‘ |
| í‰ê°€ & í†µí•© | 15ë¶„ | ëŒ€ê¸° ì¤‘ |
| **ì´ ì˜ˆìƒ ì‹œê°„** | **~3-4ì‹œê°„** | |

---

## ğŸ¯ ê²°ë¡ 

**í˜„ì¬ ìƒíƒœ**:
- âœ… Manual labeling ì™„ë²½ ì¤€ë¹„ (20 images sampled, guides created, tools ready)
- âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° ë¬¸ì„œí™” ì™„ë£Œ
- âœ… ì˜ˆìƒ ê°œì„  íš¨ê³¼ ëª…í™• (mAP 0â†’0.6-0.8, confidence 2Ã—, loss 10-20Ã—)

**ë‹¤ìŒ í–‰ë™**:
1. Roboflow ì ‘ì† ë° í”„ë¡œì íŠ¸ ìƒì„±
2. 22 keypoints ì •ì˜ (ì •í™•í•œ ìˆœì„œ!)
3. 20 images ë¼ë²¨ë§ ì‹œì‘ (2-3ì‹œê°„)

**ì˜ˆìƒ ê²°ê³¼**:
- ì˜¤ëŠ˜ ë¼ë²¨ë§ ì™„ë£Œ ì‹œ, ë‚´ì¼ í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ ê°€ëŠ¥
- 2ì¼ ë‚´ production-ready ML keypoint detector í™•ë³´

**Ready to start!** ğŸ¯

---

**ì‘ì„±**: 2025-11-15
**ì‘ì„±ì**: Claude Code Session Continuation
**ë‹¤ìŒ ë‹¨ê³„**: Roboflow ë¼ë²¨ë§ ì‹œì‘ â†’ Fine-tuning â†’ Production í†µí•©
